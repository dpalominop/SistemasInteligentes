{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uW3xc_wenY7A"
   },
   "source": [
    "## Images and Feed Forward Neural Networks\n",
    "\n",
    "\n",
    "![fmnist](https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/doc/img/fashion-mnist-sprite.png)\n",
    "\n",
    "The FMNIST dataset contains 60000 images in 10 classes: \n",
    "\n",
    "T-shirt/top\n",
    ", Trouser\n",
    ", Pullover\n",
    ", Dress\n",
    ", Coat\n",
    ", Sandal\n",
    ", Shirt\n",
    ", Sneaker\n",
    ", Bag\n",
    ", Ankle boot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XLMRPLVCFwEc"
   },
   "source": [
    "## Why Fashion-MNIST?\n",
    "\n",
    "\n",
    "*   MNIST is too easy\n",
    "*   MNIST is overused\n",
    "*   MNIST can not represent modern Computer Vision tasks\n",
    "\n",
    "Read more about the Fashion-MINST dataset in this paper [here](https://arxiv.org/abs/1708.07747) (**Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "toc",
    "id": "1jQGPl2l7kF7"
   },
   "source": [
    ">>[Why Fashion-MNIST?](#scrollTo=XLMRPLVCFwEc)\n",
    "\n",
    ">>[Download the fashion_mnist data](#scrollTo=LbCigZtNZZgl)\n",
    "\n",
    ">>[Visualize the data](#scrollTo=tWORMSC8FDR4)\n",
    "\n",
    ">>[Data normalization](#scrollTo=Zx-Ee6LHZZgt)\n",
    "\n",
    ">>[Split the data into train/validation/test data sets](#scrollTo=CFlNHktHBtru)\n",
    "\n",
    ">>[Create the model architecture](#scrollTo=HhalcO03ZZg3)\n",
    "\n",
    ">>[Compile the model](#scrollTo=FhxJ5dinZZg8)\n",
    "\n",
    ">>[Train the model](#scrollTo=DtOvh3YVZZg_)\n",
    "\n",
    ">>[Load Model with the best validation accuracy](#scrollTo=e-MGLwZQy05d)\n",
    "\n",
    ">>[Test Accuracy](#scrollTo=9RTRkan4yq5H)\n",
    "\n",
    ">>[Visualize prediction](#scrollTo=oJv7XEk10bOv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LbCigZtNZZgl"
   },
   "source": [
    "## Download the fashion_mnist data\n",
    "First let's install TensorFlow version 1.8.0 and import Tensorflow. Then we download fashion-mnist which is one of the Keras datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 48
    },
    "colab_type": "code",
    "id": "d44TznbgZZgm",
    "outputId": "6bc6acd1-4b1c-4a7a-df89-7b060c6923d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras version: 2.2.4 backend: tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!pip install -q -U tensorflow>=1.8.0\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D, Convolution2D\n",
    "from keras.layers.convolutional import Conv2D \n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "from distutils.version import LooseVersion as LV\n",
    "from keras import __version__\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Using Keras version:', __version__, 'backend:', K.backend())\n",
    "assert(LV(__version__) >= LV(\"2.0.0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-aC0M2ompNRy",
    "outputId": "4c339913-05a6-4f8b-8112-3a358ccdfb07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the fashion-mnist pre-shuffled train data and test data (have a look at tf.keras.datasets)\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWORMSC8FDR4"
   },
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "colab_type": "code",
    "id": "aFe4wHGRFKle",
    "outputId": "99367c3a-9411-4682-da64-afa3f9a1bde9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "(60000, 28, 28) train set\n",
      "(10000, 28, 28) test set\n",
      "y = 3 Dress\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training and test datasets\n",
    "print(x_train.shape, 'train set')\n",
    "print(x_test.shape, 'test set')\n",
    "\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = 5\n",
    "\n",
    "# y_train contains the lables, ranging from 0 to 9 (get image label)\n",
    "label_index = 3\n",
    "\n",
    "# Print the label, for example 2 Pullover\n",
    "print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
    "\n",
    "# # Show one of the images from the training dataset (access image)\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zx-Ee6LHZZgt"
   },
   "source": [
    "## Data normalization\n",
    "Normalize the data dimensions so that they are of approximately the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNh5NIckZZgu"
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LMSg53fiZZgx",
    "outputId": "ceca51c8-e8b9-4fa1-e4c6-82a9eebff323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data - 60000\n",
      "Number of test data - 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train data - \" + str(len(x_train)))\n",
    "print(\"Number of test data - \" + str(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFlNHktHBtru"
   },
   "source": [
    "## Split the data into train/validation/test data sets\n",
    "\n",
    "\n",
    "*   Training data - used for training the model\n",
    "*   Validation data - used for tuning the hyperparameters and evaluate the models\n",
    "*   Test data - used to test the model after the model has gone through initial vetting by the validation set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "1ShU787gZZg0",
    "outputId": "e768af7d-2f91-46f5-b65d-480a8bb338e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
      "55000 train set\n",
      "5000 validation set\n",
      "10000 test set\n"
     ]
    }
   ],
   "source": [
    "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "(x_train, x_valid) = (x_train[:55000,:,:], x_train[55000:,:,:])\n",
    "(y_train, y_valid) = (y_train[:55000], y_train[55000:])\n",
    "\n",
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape((55000, 28, 28, 1))\n",
    "x_valid = x_valid.reshape((5000, 28, 28, 1))\n",
    "x_test = x_test.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# One-hot encode the labels (hint: to_categorical)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoder.fit_transform(y_train.reshape((y_train.shape[0],1)))\n",
    "y_train = onehot_encoder.fit_transform(y_train.reshape(y_train.shape[0], 1))\n",
    "y_valid = onehot_encoder.fit_transform(y_valid.reshape(y_valid.shape[0], 1))\n",
    "y_test = onehot_encoder.fit_transform(y_test.reshape(y_test.shape[0], 1))\n",
    "\n",
    "# Print training set shape\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training, validation, and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_valid.shape[0], 'validation set')\n",
    "print(x_test.shape[0], 'test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HhalcO03ZZg3"
   },
   "source": [
    "## Create the model architecture\n",
    "\n",
    "There are two APIs for defining a model in Keras:\n",
    "1. [Sequential model API](https://keras.io/models/sequential/)\n",
    "2. [Functional API](https://keras.io/models/model/)\n",
    "\n",
    "In this notebook we are using the Sequential model API. \n",
    "If you are interested in a tutorial using the Functional API, checkout Sara Robinson's blog [Predicting the price of wine with the Keras Functional API and TensorFlow](https://medium.com/tensorflow/predicting-the-price-of-wine-with-the-keras-functional-api-and-tensorflow-a95d1c2c1b03).\n",
    "\n",
    "In defining the model we will be using some of these Keras APIs:\n",
    "*   Conv2D() [link text](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D/) - create a convolutional layer \n",
    "*   Pooling() [link text](https://keras.io/layers/pooling/) - create a pooling layer \n",
    "*   Dropout() [link text](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) - apply drop out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "colab_type": "code",
    "id": "_iA1c5z7rF6h",
    "outputId": "81f41fea-23c7-43f8-e1fa-6bc5ca34a985"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a53a1690353a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Take a look at the model summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/SI/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1252\u001b[0;31m                 \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m                 \u001b[0;34m'Build the model first by calling build() '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m                 \u001b[0;34m'or calling fit() with some data. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. "
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# number of convolutional filters to use (e.g. 32)\n",
    "nb_filters = 32\n",
    "\n",
    "# size of pooling area for max pooling (2x2)\n",
    "pool_size = (2,2)\n",
    "\n",
    "# convolution kernel size (3x3)\n",
    "kernel_size = (3,3)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "num_labels = 10\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FhxJ5dinZZg8"
   },
   "source": [
    "## Compile the model\n",
    "Configure the learning process with [compile()](https://keras.io/models/model/)  API before training the model. It receives three arguments:\n",
    "\n",
    "*   An optimizer  (e.g. Adam)\n",
    "*   A loss function \n",
    "*   A list of metrics (accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQUlOa8cZZg9"
   },
   "outputs": [],
   "source": [
    "... compile model here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtOvh3YVZZg_"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "We use  the [ModelCheckpoint](https://keras.io/callbacks/#modelcheckpoint) API to save the model after every epoch. Set \"save_best_only = True\" to save only when the validation accuracy improves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQDPZ3FYvMzk"
   },
   "outputs": [],
   "source": [
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-6MtQk7vQGW"
   },
   "outputs": [],
   "source": [
    "history = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTmapAttZZhA"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0g-ZdBRFbRW"
   },
   "source": [
    "Now let's train the model with [fit()](https://keras.io/models/sequential/) API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "-1p81T3cFS1y",
    "outputId": "9cd1c77d-40e7-4056-c18c-5a2e5cc110d9"
   },
   "outputs": [],
   "source": [
    "batch_size = ...\n",
    "nb_epochs = ...\n",
    "\n",
    "... fit model here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-MGLwZQy05d"
   },
   "source": [
    "## Load Model with the best validation accuracy\n",
    "\n",
    "Now let's train the model with [load_weights()](https://keras.io/models/about-keras-models/) API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UD1tecxUZZhE"
   },
   "outputs": [],
   "source": [
    "# Load the weights with the best validation accuracy\n",
    "... load model weights here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RTRkan4yq5H"
   },
   "source": [
    "## Test Accuracy\n",
    "\n",
    "Now let's train the model with [evaluate()](https://keras.io/models/model/) API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VZtqBqFFy62R",
    "outputId": "de5ec767-1d6d-450d-9f94-abf8f200502c"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on test set\n",
    "... evaluate model here ...\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "3f8Zt1IRu99K",
    "outputId": "e911126e-7e5f-4a2a-8108-71f4b6117753"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,11), history.acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJv7XEk10bOv"
   },
   "source": [
    "## Visualize prediction\n",
    "Now let's visualize the prediction using the model you just trained. \n",
    "First we get the predictions with the model from the test data.\n",
    "Then we print out 15 images from the test data set, and set the titles with the prediction (and the groud truth label).\n",
    "If the prediction matches the true label, the title will be green; otherwise it's displayed in red.\n",
    "\n",
    "Now let's train the model with [predict()](https://keras.io/models/model/) API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwNmlfIC0YxM"
   },
   "outputs": [],
   "source": [
    "... get y_hat predictions here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "colab_type": "code",
    "id": "btWG3nuWGSXw",
    "outputId": "bb1abc94-4a34-442e-c0da-66dbd692d6d0"
   },
   "outputs": [],
   "source": [
    "# Plot a random sample of 10 test images, their predicted labels and ground truth\n",
    "figure = plt.figure(figsize=(20, 8))\n",
    "for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    # Display each image\n",
    "    ax.imshow(np.squeeze(x_test[index]))\n",
    "    predict_index = np.argmax(y_hat[index])\n",
    "    true_index = np.argmax(y_test[index])\n",
    "    # Set the title for each image\n",
    "    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n",
    "                                  fashion_mnist_labels[true_index]),\n",
    "                                  color=(\"green\" if predict_index == true_index else \"red\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ucsp-mnistkeras.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
