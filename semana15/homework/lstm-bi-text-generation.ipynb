{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dpalominop/SistemasInteligentes/blob/master/semana15/homework/lstm-bi-text-generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_qFRwvLVL9Qs"
   },
   "source": [
    "# Test Generation using a Bidirectional LSTM Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B1Eqhf6JL9Qy"
   },
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "id": "dWcJZBNJL9Q1",
    "outputId": "0927ca51-20ba-4f47-ceb6-012c45afbcda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.16.0)\n",
      "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
      "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.11.0)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (4.28.1)\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
      "Requirement already satisfied: es_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.0.0/es_core_news_sm-2.0.0.tar.gz#egg=es_core_news_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /usr/local/lib/python3.6/dist-packages/es_core_news_sm -->\n",
      "    /usr/local/lib/python3.6/dist-packages/spacy/data/es\n",
      "\n",
      "    You can now load the model via spacy.load('es')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#import Keras library\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM, Input, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LambdaCallback\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=4, \\\n",
    "                        inter_op_parallelism_threads=4, \\\n",
    "                        allow_soft_placement=True,\\\n",
    "                        device_count = {'CPU' : 1, 'GPU' : 1})\n",
    "tf.device('/gpu:1')\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "#import spacy, and spacy french model\n",
    "# spacy is used to work on text\n",
    "!pip install spacy\n",
    "import spacy\n",
    "!python -m spacy download es\n",
    "nlp = spacy.load('es')\n",
    "\n",
    "#import other libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "import collections\n",
    "from six.moves import cPickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "bZ4qMpiRMSOs",
    "outputId": "bacf7e6c-ccb7-41a2-dfc0-a9290ecd05b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4522  100  4522    0     0  24053      0 --:--:-- --:--:-- --:--:-- 24053\n"
     ]
    }
   ],
   "source": [
    "gdrive = True\n",
    "if gdrive:\n",
    "    !pip install -U -q PyDrive\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "\n",
    "    # Authenticate and create the PyDrive client.\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "    \n",
    "    !curl https://raw.githubusercontent.com/dexterfichuk/GoogleDriveCheckpoint/master/google_drive_checkpoint.py -O\n",
    "      \n",
    "    from google_drive_checkpoint import GoogleDriveCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v77u-lhBL9RF"
   },
   "outputs": [],
   "source": [
    "#define parameters used in the tutorial\n",
    "data_dir = 'data/'# data directory containing raw texts\n",
    "save_dir = 'vocab' # directory to store trained NN models\n",
    "file_list = [\"spanish_emojis\"]\n",
    "\n",
    "if gdrive:\n",
    "    link = \"https://drive.google.com/open?id=1kdV9lTy7RNp4xYX6_IMA-6wfMRyXNSgv\"\n",
    "    fluff, id = link.split('=')\n",
    "    downloaded = drive.CreateFile({'id':id}) \n",
    "    downloaded.GetContentFile('words_vocab.pkl')\n",
    "    vocab_file = \"words_vocab.pkl\" \n",
    "    \n",
    "    link = \"https://drive.google.com/open?id=1xr0ZW6lBDTALEqaAdZefu-DwgEPIgM83\"\n",
    "    fluff, id = link.split('=')\n",
    "    downloaded = drive.CreateFile({'id':id}) \n",
    "    downloaded.GetContentFile('words_list.pkl')\n",
    "    words_list_file = \"words_list.pkl\" \n",
    "    \n",
    "    link = \"https://drive.google.com/open?id=17o5LV6AizHqPw9QeIjKwFXmTASpNs673\"\n",
    "    fluff, id = link.split('=')\n",
    "    downloaded = drive.CreateFile({'id':id}) \n",
    "    downloaded.GetContentFile('spanish_emojis.csv')\n",
    "    data_file = \"spanish_emojis.csv\"\n",
    "    \n",
    "    link = \"https://drive.google.com/open?id=1gTUqnhuknwFP4BIFQixRIjB7V-CQyb_r\"\n",
    "    fluff, id = link.split('=')\n",
    "    downloaded = drive.CreateFile({'id':id}) \n",
    "    downloaded.GetContentFile('sequences_list.pkl')\n",
    "    sequences_file = \"sequences_list.pkl\" \n",
    "    \n",
    "    link = \"https://drive.google.com/open?id=13NEQdiBBn-3vCy8Q5JF-OBzrD7hs680j\"\n",
    "    fluff, id = link.split('=')\n",
    "    downloaded = drive.CreateFile({'id':id}) \n",
    "    downloaded.GetContentFile('next_words_list.pkl')\n",
    "    next_words_file = \"next_words_list.pkl\"\n",
    "    \n",
    "else:   \n",
    "    vocab_file = os.path.join(data_dir, \"words_vocab.pkl\")\n",
    "    words_list_file = os.path.join(data_dir, \"words_list.pkl\")\n",
    "    data_file = os.path.join(data_dir, file_list[0] + \".csv\")\n",
    "    sequences_file = os.path.join(data_dir, \"sequences_list.pkl\")\n",
    "    next_words_file = os.path.join(data_dir, \"next_words_list.pkl\")\n",
    "\n",
    "sequences_step = 1 #step to create sequences\n",
    "seq_length = 10 # sequence length\n",
    "preprocess = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "herJ9AX3L9RO"
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    items = []\n",
    "    if os.path.exists(filename):\n",
    "        # try:\n",
    "        with open(filename, 'rb') as fname:\n",
    "            while True:\n",
    "                try:\n",
    "                    items = cPickle.load(fname)\n",
    "                except EOFError:\n",
    "                    print(EOFError)\n",
    "                    break\n",
    "    else:\n",
    "        items = []\n",
    "    \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CaMf9GfIL9RU"
   },
   "outputs": [],
   "source": [
    "def create_wordlist(doc):\n",
    "    wl = []\n",
    "    for word in doc:\n",
    "        if word.text not in (\"\\n\",\"\\n\\n\",'\\u2009','\\xa0'):\n",
    "            wl.append(word.text.lower())\n",
    "    return wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lmDYsfBLL9RZ"
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "next_words = []\n",
    "wordlist = []\n",
    "if(preprocess):\n",
    "    input_file = pd.read_csv(data_file)\n",
    "    lines = input_file['observations']\n",
    "    for data in lines:\n",
    "        #create sentences\n",
    "        doc = nlp(data)\n",
    "        wl = create_wordlist(doc)\n",
    "        wordlist = wordlist + wl\n",
    "        if(len(wl) < 2): \n",
    "            continue\n",
    "        seq = [' ' for i in range(seq_length - len(wl) + 1)]\n",
    "        seq = seq + wl\n",
    "\n",
    "        for i in range(0, len(seq) - seq_length, sequences_step):\n",
    "          sequences.append(seq[i: i + seq_length])\n",
    "          next_words.append(seq[i + seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYPBqN0JL9Rf"
   },
   "outputs": [],
   "source": [
    "if(preprocess):\n",
    "    # count the number of words\n",
    "    word_counts = collections.Counter(wordlist)\n",
    "\n",
    "    # Mapping from index to word : that's the vocabulary\n",
    "    vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "    vocabulary_inv = list(sorted(vocabulary_inv))\n",
    "\n",
    "    # Mapping from word to index\n",
    "    vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "    words = [x[0] for x in word_counts.most_common()]\n",
    "\n",
    "    #size of the vocabulary\n",
    "    vocab_size = len(words)\n",
    "    print(\"vocab size: \", vocab_size)\n",
    "\n",
    "    #save the words and vocabulary\n",
    "    with open(os.path.join(vocab_file), 'wb') as f:\n",
    "        cPickle.dump((words, vocab, vocabulary_inv), f)\n",
    "    with open(os.path.join(words_list_file), 'wb') as f:\n",
    "        cPickle.dump((wordlist), f)\n",
    "    with open(os.path.join(sequences_file), 'wb') as f:\n",
    "        cPickle.dump((sequences), f)\n",
    "    with open(os.path.join(next_words_file), 'wb') as f:\n",
    "        cPickle.dump((next_words), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "l--bcrWRL9Rl",
    "outputId": "97a84890-3783-4af3-9123-8c284781178f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'EOFError'>\n",
      "<class 'EOFError'>\n",
      "<class 'EOFError'>\n",
      "<class 'EOFError'>\n",
      "vocab size:  66846\n"
     ]
    }
   ],
   "source": [
    "if(not preprocess):\n",
    "    wordlist = read_file(words_list_file)\n",
    "    (words, vocab, vocabulary_inv) = read_file(vocab_file)\n",
    "    sequences = read_file(sequences_file)\n",
    "    next_words = read_file(next_words_file)\n",
    "    \n",
    "    # count the number of words\n",
    "    word_counts = collections.Counter(wordlist)\n",
    "    \n",
    "    #size of the vocabulary\n",
    "    vocab_size = len(words)\n",
    "    print(\"vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "4rN3yd8QL9Rv",
    "outputId": "c7a050d5-10fa-43f2-e31c-72c8496dcdf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences:  421621\n",
      "vocav( ):  0\n",
      "words(0):   \n"
     ]
    }
   ],
   "source": [
    "#create sequences\n",
    "#sequences = []\n",
    "#next_words = []\n",
    "#for i in range(0, len(wordlist) - seq_length, sequences_step):\n",
    "#    sequences.append(wordlist[i: i + seq_length])\n",
    "#    next_words.append(wordlist[i + seq_length])\n",
    "\n",
    "print('nb sequences: ', len(sequences))\n",
    "print('vocav( ): ', vocab[' '])\n",
    "print('words(0): ', vocabulary_inv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-iEN3bNgL9R_"
   },
   "outputs": [],
   "source": [
    "def bidirectional_lstm_model(seq_length, vocab_size):\n",
    "    print('Build LSTM model.')\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(rnn_size, activation=\"relu\"),input_shape=(seq_length, vocab_size)))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5akgUQYLL9SI"
   },
   "outputs": [],
   "source": [
    "rnn_size = 256 # size of RNN\n",
    "batch_size = 32 # minibatch size\n",
    "seq_length = 10 # sequence length\n",
    "num_epochs = 10 # number of epochs\n",
    "learning_rate = 0.001 #learning rate\n",
    "sequences_step = 1 #step to create sequences\n",
    "BATCH_GEN = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "cYYiskZQL9SM",
    "outputId": "1101a911-1c78-4584-d13a-3f37ce610ac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build LSTM model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 512)               137426944 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 66846)             34291998  \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 66846)             0         \n",
      "=================================================================\n",
      "Total params: 171,718,942\n",
      "Trainable params: 171,718,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "md = bidirectional_lstm_model(seq_length, vocab_size)\n",
    "md.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6RDgEznwzVE"
   },
   "outputs": [],
   "source": [
    "def generator(sentence_list, next_word_list, batch_size):\n",
    "    index = 0\n",
    "    while True:\n",
    "        x = np.zeros((batch_size, seq_length, len(words)), dtype=np.bool)\n",
    "        y = np.zeros((batch_size, len(words)), dtype=np.bool)\n",
    "        for i in range(batch_size):\n",
    "            for t, w in enumerate(sentence_list[index]):\n",
    "                x[i, t, vocab[w]] = 1\n",
    "            y[i, vocab[next_words[index]]] = 1\n",
    "\n",
    "            index = index + 1\n",
    "            if index == len(sentence_list):\n",
    "                index = 0\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBvSvUgjwzVI"
   },
   "outputs": [],
   "source": [
    "file_path = \"BI-LSTM-epoch{epoch:03d}-words%d-sequence%d-loss{loss:.4f}-acc{acc:.4f}-val_loss{val_loss:.4f}-val_acc{val_acc:.4f}\" % (\n",
    "    len(words),\n",
    "    seq_length\n",
    ")\n",
    "#checkpoint = ModelCheckpoint(file_path, monitor='val_acc', save_best_only=True)\n",
    "checkpoint = GoogleDriveCheckpoint(file_path, drive, save_best_only=True, save_weights_only=True, verbose=1, mode='auto')\n",
    "\n",
    "#print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "callbacks_list = [checkpoint, \n",
    "                  #print_callback, \n",
    "                  early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "CQxZQxwQwzVN",
    "outputId": "20537fe5-c734-42ed-e549-6fde6b742cd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   8/1687 [..............................] - ETA: 18:42:13 - loss: 11.1050 - categorical_accuracy: 0.0220"
     ]
    }
   ],
   "source": [
    "md.fit_generator(\n",
    "    generator(sequences, next_words, BATCH_GEN),\n",
    "    steps_per_epoch=int(len(sequences)/BATCH_GEN) + 1,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=callbacks_list,\n",
    "    #validation_split=0.02,\n",
    "    #shuffle=True,\n",
    "    #validation_data=generator(sentences_test, next_words_test, BATCH_SIZE),\n",
    "    #validation_steps=int(len(sentences_test)/BATCH_SIZE) + 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gGn31PVL9Sb"
   },
   "outputs": [],
   "source": [
    "]#save the model\n",
    "md.save(save_dir + \"/\" + 'my_model_gen_sentences_lstm.final.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vb770U0-L9Sj"
   },
   "outputs": [],
   "source": [
    "#load vocabulary\n",
    "print(\"loading vocabulary...\")\n",
    "# vocab_file = os.path.join(save_dir, \"words_vocab.pkl\")\n",
    "\n",
    "with open(vocab_file, 'rb') as f:\n",
    "        words, vocab, vocabulary_inv = cPickle.load(f)\n",
    "\n",
    "vocab_size = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KzcfeWZUL9Sq"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# load the model\n",
    "print(\"loading model...\")\n",
    "model = load_model(save_dir + \"/\" + 'my_model_gen_sentences_lstm.final.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UY6hpEXtL9S3"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwelZdCtL9TC"
   },
   "outputs": [],
   "source": [
    "#initiate sentences\n",
    "#seed_sentences = \"estoy muy cansado para estudiar hoy\"\n",
    "seed_sentences = \"como estas\"\n",
    "generated = ''\n",
    "sentence = []\n",
    "for i in range (seq_length):\n",
    "    sentence.append(\".\")\n",
    "\n",
    "seed = seed_sentences.split()\n",
    "\n",
    "for i in range(len(seed)):\n",
    "    sentence[seq_length-i-1]=seed[len(seed)-i-1]\n",
    "\n",
    "generated += ' '.join(sentence)\n",
    "print('Generating text with the following seed: \"' + ' '.join(sentence) + '\"')\n",
    "\n",
    "print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMsI0aX-L9TL"
   },
   "outputs": [],
   "source": [
    "words_number = 10\n",
    "#generate the text\n",
    "for i in range(words_number):\n",
    "    #create the vector\n",
    "    x = np.zeros((1, seq_length, vocab_size))\n",
    "    for t, word in enumerate(sentence):\n",
    "        x[0, t, vocab[word]] = 1.\n",
    "    #print(x.shape)\n",
    "\n",
    "    #calculate next word\n",
    "    preds = md.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, 0.34)\n",
    "    next_word = vocabulary_inv[next_index]\n",
    "\n",
    "    #add the next word to the text\n",
    "    generated += \" \" + next_word\n",
    "    # shift the sentence by one, and and the next word at its end\n",
    "    sentence = sentence[1:] + [next_word]\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-uuJp8qCL9TU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "lstm-bi-text-generation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
